{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e3dc349-949b-44f2-92d8-73b1aaa93d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fd28c51-9396-4cd0-baac-d5e7b14f97da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the image dataset to PyTorch tensors and Normalize it using mean and std.\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "# download dataset\n",
    "train_ds = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
    "test_ds  = datasets.MNIST(root='data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae47f99a-c739-4f1b-9ffe-486b6b711a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(train_ds), len(test_ds))   # 60000, 10000\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=1000, shuffle=False)\n",
    "\n",
    "# visualize 6 images\n",
    "examples = iter(train_loader)\n",
    "images, labels = next(examples)\n",
    "fig, axs = plt.subplots(1,6, figsize=(10,2))\n",
    "for i in range(6):\n",
    "    axs[i].imshow(images[i].squeeze(), cmap='gray')\n",
    "    axs[i].set_title(int(labels[i].item()))\n",
    "    axs[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cba1aa-8d53-46b0-a558-45fd6d541c28",
   "metadata": {},
   "source": [
    "# Nueral network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "308fc5d9-9565-48b1-8514-4f6f8dff3e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# reproducibility(without this training might give slightly different results in each run)\n",
    "torch.manual_seed(42); np.random.seed(42); random.seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28*28, 256) #fully connected\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.out = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "760f7b9d-0b63-49f6-9ae1-4e7c2d8f80bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(xb)\n",
    "        loss = criterion(out, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "        preds = out.argmax(dim=1)\n",
    "        correct += (preds == yb).sum().item()\n",
    "        total += xb.size(0)\n",
    "    return total_loss/total, correct/total\n",
    "\n",
    "def eval_model(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            out = model(xb)\n",
    "            loss = criterion(out, yb)\n",
    "            total_loss += loss.item() * xb.size(0)\n",
    "            preds = out.argmax(dim=1)\n",
    "            correct += (preds == yb).sum().item()\n",
    "            total += xb.size(0)\n",
    "    return total_loss/total, correct/total\n",
    "\n",
    "model = MLP().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a0b81a1-a163-4cf8-ad1b-588a6bf22741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | train_loss 0.2576 acc 0.9218  | test_loss 0.1112 acc 0.9639\n",
      "Epoch 2 | train_loss 0.1177 acc 0.9641  | test_loss 0.1431 acc 0.9519\n",
      "Epoch 3 | train_loss 0.0892 acc 0.9722  | test_loss 0.0889 acc 0.9727\n",
      "Epoch 4 | train_loss 0.0728 acc 0.9767  | test_loss 0.0843 acc 0.9750\n",
      "Epoch 5 | train_loss 0.0657 acc 0.9788  | test_loss 0.0738 acc 0.9769\n",
      "Epoch 6 | train_loss 0.0559 acc 0.9818  | test_loss 0.0723 acc 0.9792\n",
      "Epoch 7 | train_loss 0.0516 acc 0.9827  | test_loss 0.0710 acc 0.9786\n",
      "Epoch 8 | train_loss 0.0470 acc 0.9845  | test_loss 0.0795 acc 0.9798\n",
      "Epoch 9 | train_loss 0.0428 acc 0.9857  | test_loss 0.0672 acc 0.9823\n",
      "Epoch 10 | train_loss 0.0413 acc 0.9862  | test_loss 0.0777 acc 0.9800\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "epochs = 10\n",
    "for epoch in range(1, epochs+1):\n",
    "    train_loss, train_acc = train_epoch(train_loader)\n",
    "    val_loss, val_acc = eval_model(test_loader)\n",
    "    print(f\"Epoch {epoch} | train_loss {train_loss:.4f} acc {train_acc:.4f}  | test_loss {val_loss:.4f} acc {val_acc:.4f}\")\n",
    "\n",
    "# save\n",
    "torch.save(model.state_dict(), 'mlp_mnist.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e07fb09-6dab-4aff-abc1-4574c09f43d8",
   "metadata": {},
   "source": [
    "# Visualize Mistakes and confusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c018c193-4a98-4bc0-8bf2-133b521a1943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.98      0.98      0.98      1032\n",
      "           3       0.98      0.98      0.98      1010\n",
      "           4       0.98      0.99      0.98       982\n",
      "           5       0.98      0.97      0.98       892\n",
      "           6       0.99      0.98      0.98       958\n",
      "           7       0.98      0.97      0.98      1028\n",
      "           8       0.97      0.98      0.97       974\n",
      "           9       0.97      0.97      0.97      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n",
      "[[ 973    0    1    0    0    0    3    0    2    1]\n",
      " [   0 1119    2    2    0    1    1    1    9    0]\n",
      " [   4    1 1008    3    2    0    0    7    7    0]\n",
      " [   0    0    2  994    0    1    0    5    1    7]\n",
      " [   1    0    4    0  968    0    4    1    0    4]\n",
      " [   4    0    0    8    1  868    1    0    6    4]\n",
      " [   4    2    1    1    1    8  937    0    4    0]\n",
      " [   2    4    9    3    0    0    0 1002    2    6]\n",
      " [   4    0    1    2    5    2    1    3  952    4]\n",
      " [   1    4    1    3   15    3    0    1    2  979]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# collect predictions on test set\n",
    "model.eval()\n",
    "ys, ypreds = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        out = model(xb)\n",
    "        preds = out.argmax(dim=1).cpu().numpy()\n",
    "        ypreds.extend(preds)\n",
    "        ys.extend(yb.numpy())\n",
    "\n",
    "print(classification_report(ys, ypreds))\n",
    "cm = confusion_matrix(ys, ypreds)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff3e5ce1-d458-48c5-9d9d-46ad921015e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cpu\n"
     ]
    }
   ],
   "source": [
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# reproducibility(without this training might give slightly different results in each run)\n",
    "torch.manual_seed(42); np.random.seed(42); random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using:\", device)\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # 28x28 -> 28x28\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) # -> 28x28\n",
    "        self.pool = nn.MaxPool2d(2, 2)                           # -> 14x14\n",
    "        self.drop = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(64*14*14//4, 128)  # careful on sizes (we'll use a pooling twice or adapt)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.drop(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# A simpler, well-behaved CNN:\n",
    "class BetterCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                 # 14x14\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                 # 7x7\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*7*7, 128), nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "    def forward(self, x): return self.layers(x)\n",
    "\n",
    "model = BetterCNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50eff208-f870-4270-9253-707bc5ff44c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.1612, Accuracy=95.02%\n",
      "Epoch 2: Train Loss=0.0531, Accuracy=98.38%\n",
      "Epoch 3: Train Loss=0.0367, Accuracy=98.83%\n",
      "Epoch 4: Train Loss=0.0289, Accuracy=99.08%\n",
      "Epoch 5: Train Loss=0.0242, Accuracy=99.23%\n",
      "Epoch 6: Train Loss=0.0192, Accuracy=99.37%\n",
      "Epoch 7: Train Loss=0.0175, Accuracy=99.43%\n",
      "Epoch 8: Train Loss=0.0143, Accuracy=99.55%\n",
      "Epoch 9: Train Loss=0.0115, Accuracy=99.62%\n",
      "Epoch 10: Train Loss=0.0120, Accuracy=99.57%\n",
      "Epoch 11: Train Loss=0.0101, Accuracy=99.66%\n",
      "Epoch 12: Train Loss=0.0085, Accuracy=99.73%\n",
      "Epoch 13: Train Loss=0.0080, Accuracy=99.72%\n",
      "Epoch 14: Train Loss=0.0081, Accuracy=99.73%\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "epochs = 14\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss, correct = 0, 0\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += pred.eq(target).sum().item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: \"\n",
    "          f\"Train Loss={train_loss/len(train_loader):.4f}, \"\n",
    "          f\"Accuracy={100. * correct/len(train_ds):.2f}%\")\n",
    "torch.save(model.state_dict(), \"cnn_mnist.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a2e60f-e383-4a4f-a46c-af8c39026489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
